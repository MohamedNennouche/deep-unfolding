{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code run on : cpu\n"
     ]
    }
   ],
   "source": [
    "from utils import device, generate_A_H_sol, decompose_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number, min. and max. eigenvalues of A:\n",
      "30.828752475024576 5.678370598467175 0.18419073567986302\n"
     ]
    }
   ],
   "source": [
    "# # ! Tout ca devrait Ãªtre des variables\n",
    "total_itr = 25  # Total number of iterations (multiple of \"itr\")\n",
    "n = 300  # Number of rows # ? suppose to be a variable ?\n",
    "m = 600  # Number of columns # ? suppose to be a variable ?\n",
    "bs = 10000  # Mini-batch size (samples)\n",
    "num_batch = 500  # Number of mini-batches\n",
    "lr_adam = 0.002  # Learning rate of optimizer\n",
    "init_val_SORNet = 1.1  # Initial value of omega for SORNet\n",
    "init_val_SOR_CHEBY_Net_omega = 0.6  # Initial value of omega for SOR_CHEBY_Net\n",
    "init_val_SOR_CHEBY_Net_gamma = 0.8  # Initial value of gamma for SOR_CHEBY_Net\n",
    "init_val_SOR_CHEBY_Net_alpha = 0.9  # Initial value of alpha for SOR_CHEBY_Net\n",
    "init_val_AORNet_r = 0.9  # Initial value of r for AORNet\n",
    "init_val_AORNet_omega = 1.5  # Initial value of omega for AORNet\n",
    "init_val_RINet = 0.1  # Initial value of omega for RINet\n",
    "\n",
    "# Generate A and H\n",
    "seed = 12\n",
    "\n",
    "A, H, W, solution, y = generate_A_H_sol(n=n, m=m, seed=seed, bs=bs)\n",
    "A, D, L, U, Dinv, Minv = decompose_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SORNet(nn.Module):\n",
    "    \"\"\"Deep unfolded SOR with a constant step size.\"\"\"\n",
    "\n",
    "    def __init__(self, init_val_SORNet, A, H, bs, y, device=device):\n",
    "        \"\"\"\n",
    "        Initialize the SORNet model.\n",
    "\n",
    "        Args:\n",
    "            num_itr (int): Number of iterations.\n",
    "            init_val_SORNet (float): Initial value for inv_omega.\n",
    "            D (torch.Tensor): Diagonal matrix D.\n",
    "            L (torch.Tensor): Lower triangular matrix L.\n",
    "            U (torch.Tensor): Upper triangular matrix U.\n",
    "            H (torch.Tensor): Matrix H.\n",
    "            bs (int): Batch Size\n",
    "            y (toch.Tensor): Solution\n",
    "            device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "        \"\"\"\n",
    "        super(SORNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.inv_omega = nn.Parameter(torch.tensor(init_val_SORNet, device=device))\n",
    "        \n",
    "        A, D, L, U, _, _ = decompose_matrix(A)\n",
    "        \n",
    "        self.A = A.to(device)\n",
    "        self.D = D.to(device)\n",
    "        self.L = L.to(device)\n",
    "        self.U = U.to(device)\n",
    "        self.H = H.to(device)\n",
    "        self.Dinv = torch.linalg.inv(D).to(device)\n",
    "        self.bs = bs\n",
    "        self.y = y.to(device)\n",
    "\n",
    "    def forward(self, num_itr):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the SORNet model.\n",
    "\n",
    "        Args:\n",
    "            bs (int): Batch size.\n",
    "            y (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "            list: List of intermediate results.\n",
    "\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "\n",
    "        invM = torch.linalg.inv(self.inv_omega * self.D + self.L)\n",
    "        s = torch.zeros(self.bs, self.H.size(1), device=self.device)\n",
    "        traj.append(s)\n",
    "        yMF = torch.matmul(self.y, self.H.T)\n",
    "        s = torch.matmul(yMF, self.Dinv)\n",
    "\n",
    "        for _ in range(num_itr):\n",
    "            temp = torch.matmul(s, (self.inv_omega - 1) * self.D - self.U) + yMF\n",
    "            s = torch.matmul(temp, invM)\n",
    "            traj.append(s)\n",
    "\n",
    "        return s, traj\n",
    "\n",
    "# ========================================================================================================\n",
    "\n",
    "class SOR_CHEBY_Net(nn.Module):\n",
    "    \"\"\"Deep unfolded SOR with Chebyshev acceleration.\"\"\"\n",
    "\n",
    "    def __init__(self, num_itr, init_val_SOR_CHEBY_Net_omega, init_val_SOR_CHEBY_Net_gamma, init_val_SOR_CHEBY_Net_alpha, A, H, bs, y, device=device):\n",
    "        \"\"\"\n",
    "        Initialize the SOR_CHEBY_Net model.\n",
    "\n",
    "        Args:\n",
    "            num_itr (int): Number of iterations.\n",
    "            init_val_SOR_CHEBY_Net_omega (float): Initial value for omega.\n",
    "            init_val_SOR_CHEBY_Net_gamma (float): Initial value for gamma.\n",
    "            init_val_SOR_CHEBY_Net_alpha (float): Initial value for inv_omega.\n",
    "            D (torch.Tensor): Diagonal matrix D.\n",
    "            L (torch.Tensor): Lower triangular matrix L.\n",
    "            U (torch.Tensor): Upper triangular matrix U.\n",
    "            H (torch.Tensor): Matrix H.\n",
    "            bs (int): Batch Size\n",
    "            y (torch.Tensor): Solution of the linear equation\n",
    "            device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "        \"\"\"\n",
    "        super(SOR_CHEBY_Net, self).__init__()\n",
    "        self.device = device\n",
    "        self.gamma = nn.Parameter(init_val_SOR_CHEBY_Net_gamma * torch.ones(num_itr, device=device))\n",
    "        self.omega = nn.Parameter(init_val_SOR_CHEBY_Net_omega * torch.ones(num_itr, device=device))\n",
    "        self.inv_omega = nn.Parameter(torch.tensor(init_val_SOR_CHEBY_Net_alpha, device=device))\n",
    "        \n",
    "        A, D, L, U, _, _ = decompose_matrix(A)\n",
    "        self.A = A\n",
    "        self.D = D.to(device)\n",
    "        self.L = L.to(device)\n",
    "        self.U = U.to(device)\n",
    "        self.H = H.to(device)\n",
    "        self.Dinv = torch.linalg.inv(D).to(device)\n",
    "        self.bs = bs\n",
    "        self.y = y.to(device)\n",
    "\n",
    "    def forward(self, num_itr):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the SOR_CHEBY_Net model.\n",
    "\n",
    "        Args:\n",
    "            bs (int): Batch size.\n",
    "            y (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "            list: List of intermediate results.\n",
    "\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "\n",
    "        invM = torch.linalg.inv(self.inv_omega * self.D + self.L)\n",
    "        s = torch.zeros(self.bs, self.H.size(1), device=self.device)\n",
    "        s_new = torch.zeros(self.bs, self.H.size(1), device=self.device)\n",
    "        traj.append(s)\n",
    "        yMF = torch.matmul(self.y, self.H.T)\n",
    "        s = torch.matmul(yMF, self.Dinv)\n",
    "        s_present = s\n",
    "        s_old = torch.zeros_like(s_present)\n",
    "\n",
    "        for i in range(num_itr):\n",
    "            temp = torch.matmul(s, (self.inv_omega - 1) * self.D - self.U) + yMF\n",
    "            s = torch.matmul(temp, invM)\n",
    "\n",
    "            s_new = self.omega[i] * (self.gamma[i] * (s - s_present) + (s_present - s_old)) + s_old\n",
    "            s_old = s\n",
    "            s_present = s_new\n",
    "            traj.append(s_new)\n",
    "\n",
    "        return s_new, traj\n",
    "\n",
    "# =====================================================================================\n",
    "\n",
    "class AORNet(nn.Module):\n",
    "    \"\"\"Deep unfolded AOR with a constant step size.\"\"\"\n",
    "\n",
    "    def __init__(self, init_val_AORNet_r, init_val_AORNet_omega, A, H, bs, y, device=device):\n",
    "        \"\"\"\n",
    "        Initialize the AORNet model.\n",
    "\n",
    "        Args:\n",
    "            init_val_AORNet_r (float): Initial value for r.\n",
    "            init_val_AORNet_omega (float): Initial value for omega.\n",
    "            D (torch.Tensor): Diagonal matrix D.\n",
    "            L (torch.Tensor): Lower triangular matrix L.\n",
    "            U (torch.Tensor): Upper triangular matrix U.\n",
    "            H (torch.Tensor): Matrix H.\n",
    "            device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        super(AORNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.r = nn.Parameter(torch.tensor(init_val_AORNet_r, device=device))\n",
    "        self.omega = nn.Parameter(torch.tensor(init_val_AORNet_omega, device=device))\n",
    "        \n",
    "        A, D, L, U, _, _ = decompose_matrix(A)\n",
    "        self.A = A.to(device)\n",
    "        self.D = D.to(device)\n",
    "        self.L = L.to(device)\n",
    "        self.U = U.to(device)\n",
    "        self.H = H.to(device)\n",
    "        self.Dinv = torch.linalg.inv(D).to(device)\n",
    "        self.bs = bs\n",
    "        self.y = y\n",
    "\n",
    "    def forward(self, num_itr):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the AORNet model.\n",
    "\n",
    "        Args:\n",
    "            num_itr (int): Number of iterations.\n",
    "            bs (int): Batch size.\n",
    "            y (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "            list: List of intermediate results.\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "\n",
    "        invM = torch.linalg.inv(self.L - self.r * self.D)\n",
    "        N = (1 - self.omega) * self.D + (self.omega - self.r) * self.L + self.omega * self.U\n",
    "        s = torch.zeros(self.bs, self.H.size(1), device=self.device)\n",
    "        traj.append(s)\n",
    "        yMF = torch.matmul(self.y, self.H.T)\n",
    "        s = torch.matmul(yMF, self.Dinv)\n",
    "\n",
    "        for _ in range(num_itr):\n",
    "            s = torch.matmul(s, torch.matmul(invM, N)) + torch.matmul(yMF, invM)\n",
    "            traj.append(s)\n",
    "\n",
    "        return s, traj\n",
    "\n",
    "# =====================================================================================\n",
    "\n",
    "class RINet(nn.Module):\n",
    "    \"\"\"Deep unfolded Richardson iteration.\"\"\"\n",
    "\n",
    "    def __init__(self, init_val_RINet, A, H, bs, y, device=device):\n",
    "        \"\"\"\n",
    "        Initialize the RINet model.\n",
    "\n",
    "        Args:\n",
    "            num_itr (int): Number of iterations.\n",
    "\n",
    "        \"\"\"\n",
    "        super(RINet, self).__init__()\n",
    "        self.inv_omega = nn.Parameter(torch.tensor(init_val_RINet, device=device))\n",
    "        \n",
    "        A, D, L, U, _, _ = decompose_matrix(A)\n",
    "        self.A = A.to(device)\n",
    "        self.D = D.to(device)\n",
    "        self.L = L.to(device)\n",
    "        self.U = U.to(device)\n",
    "        self.H = H.to(device)\n",
    "        self.Dinv = torch.linalg.inv(D).to(device)\n",
    "        self.bs = bs\n",
    "        self.y = y\n",
    "\n",
    "    def forward(self, num_itr):\n",
    "        \"\"\"\n",
    "        Perform forward pass of the RINet model.\n",
    "\n",
    "        Args:\n",
    "            num_itr (int): Number of iterations.\n",
    "            bs (int): Batch size.\n",
    "            y (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "            list: List of intermediate results.\n",
    "\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "\n",
    "        s = torch.zeros(self.bs, A.shape[0]).to(device)\n",
    "        traj.append(s)\n",
    "        yMF = torch.matmul(self.y, self.H.T)\n",
    "        s = torch.matmul(yMF, self.Dinv)\n",
    "\n",
    "        for _ in range(num_itr):\n",
    "            s = s + torch.mul(self.inv_omega[0], (yMF - torch.matmul(s, self.A)))\n",
    "            traj.append(s)\n",
    "\n",
    "        return s, traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# Models\n",
    "model_SorNet = SORNet(init_val_SORNet, A, H, bs, y, device=device)\n",
    "model_Sor_Cheby_Net = SOR_CHEBY_Net(total_itr, init_val_SOR_CHEBY_Net_omega, init_val_SOR_CHEBY_Net_gamma, init_val_SOR_CHEBY_Net_alpha, A, H, bs, y, device=device)\n",
    "model_AorNet = AORNet(init_val_AORNet_r, init_val_AORNet_omega, A, H, bs, y, device=device)\n",
    "model_RINet = RINet( init_val_RINet, A, H, bs, y, device=device)\n",
    "\n",
    "# Optimizers\n",
    "opt_SORNet = optim.Adam(model_SorNet.parameters(), lr=lr_adam)\n",
    "opt_SORNet_Cheby = optim.Adam(model_Sor_Cheby_Net.parameters(), lr=lr_adam)\n",
    "opt_AORNet = optim.Adam(model_AorNet.parameters(), lr=lr_adam)\n",
    "opt_RINet = optim.Adam(model_RINet.parameters(), lr=lr_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1  batch: 0 \t MSE loss: 1.791316032409668\n",
      "generation: 1  batch: 200 \t MSE loss: 1.7642379999160767\n",
      "generation: 1  batch: 400 \t MSE loss: 1.762949824333191\n",
      "generation: 2  batch: 0 \t MSE loss: 1.7931795120239258\n",
      "generation: 2  batch: 200 \t MSE loss: 1.7605116367340088\n",
      "generation: 2  batch: 400 \t MSE loss: 1.7603600025177002\n",
      "generation: 3  batch: 0 \t MSE loss: 1.7796863317489624\n",
      "generation: 3  batch: 200 \t MSE loss: 1.7681561708450317\n",
      "generation: 3  batch: 400 \t MSE loss: 1.7641069889068604\n",
      "generation: 4  batch: 0 \t MSE loss: 1.777740478515625\n",
      "generation: 4  batch: 200 \t MSE loss: 1.7655141353607178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m solution \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(bs, n), \u001b[38;5;241m1.0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m solution \u001b[38;5;241m@\u001b[39m H\n\u001b[1;32m---> 14\u001b[0m x_hat, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_SorNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(x_hat, solution)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\dell\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dell\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m, in \u001b[0;36mSORNet.forward\u001b[1;34m(self, num_itr)\u001b[0m\n\u001b[0;32m     52\u001b[0m traj\u001b[38;5;241m.\u001b[39mappend(s)\n\u001b[0;32m     53\u001b[0m yMF \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 54\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43myMF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDinv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_itr):\n\u001b[0;32m     57\u001b[0m     temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(s, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minv_omega \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU) \u001b[38;5;241m+\u001b[39m yMF\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_gen=[]\n",
    "for gen in range(total_itr):\n",
    "    \"\"\"\n",
    "    Training process of SORNet.\n",
    "\n",
    "    Args:\n",
    "        gen (int): Generation number.\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(num_batch):\n",
    "        opt_SORNet.zero_grad()\n",
    "        solution = torch.normal(0.0 * torch.ones(bs, n), 1.0).to(device)\n",
    "        y = solution @ H\n",
    "        x_hat, _ = model_SorNet(gen + 1)\n",
    "        loss = loss_func(x_hat, solution)\n",
    "        loss.backward()\n",
    "        opt_SORNet.step()\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(\"generation:\", gen + 1, \" batch:\", i, \"\\t MSE loss:\", loss.item())\n",
    "\n",
    "    loss_gen.append(loss.item())\n",
    "## training process of SOR_CHEBY_Net\n",
    "# it takes about several minutes on Google Colaboratory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
